# $FreeBSD: stable/10/etc/sysctl.conf 112200 2003-03-13 18:43:50Z mux $
#
#  This file is read when going to multi-user and its contents piped thru
#  ``sysctl'' to adjust kernel values.  ``man 5 sysctl.conf'' for details.
#

# low latency is important so we highly recommend that you disable hyper
# threading on Intel CPUs as it has an unpredictable affect on latency, cpu
# cache misses and load.
#
# These settings are specifically tuned for a low latency FIOS (300/65) and
# gigabit LAN connections. If you have 10gig or 40gig you will need to increase
# the network buffers as well.
#

# General network tuning
# https://wiki.freebsd.org/NetworkPerformanceTuning
kern.random.sys.harvest.ethernet=0
kern.random.sys.harvest.point_to_point=0
kern.random.sys.harvest.interrupt=0

# Before tuning the following two(2) sections on maxsockbuf and buf_max take a
# some time to read PSC's tips on Enabling High Performance Data Transfers.
# http://www.psc.edu/index.php/networking/641-tcp-tune

# set to at least 16MB for 10GE and high speed 1GE hosts as well as to increase
# the TCP window size to 65535 and window scale to 9. For 10GE hosts with RTT
# over 100ms you will need to set to 160MB and a wscale of 12. Default "2097152
# = 2*1024*1024" is fine for most 1Gbit connections or less.
# network:   1 Gbit   maxsockbuf:    2MB   wsize:  6    2^7*65KB =    8MB
# network:  10 Gbit   maxsockbuf:   16MB   wsize:  9    2^9*65KB =   32MB
# network:  40 Gbit   maxsockbuf:  150MB   wsize: 12   2^12*65KB =  260MB
# network: 100 Gbit   maxsockbuf:  600MB   wsize: 14   2^14*65KB = 1064MB
kern.ipc.maxsockbuf=16777216  # (default 2097152)

# set auto tuning maximum to at least 16MB for 10GE hosts with RTT of less then
# 100ms. For 10GE hosts with RTT of greater then 100ms set buf_max to 160MB.
# The default of  "2097152" is fine for 1Gb.
net.inet.tcp.sendbuf_max=16777216  # (default 2097152)
net.inet.tcp.recvbuf_max=16777216  # (default 2097152)

# use the H-TCP congestion control algorithm which is more aggressive pushing
# up to max bandwidth (total BDP) and favors hosts with lower TTL / VARTTL then
# the default "newreno". Understand "newreno" works well in most conditions and
# enabling HTCP may only gain a you few percentage points of throughput. We
# suggest testing both, but we prefer HTCP.
# http://www.sigcomm.org/sites/default/files/ccr/papers/2008/July/1384609-1384613.pdf
# make sure to also add 'cc_htcp_load="YES"' to /boot/loader.conf then check
# available congestion control options with "sysctl net.inet.tcp.cc.available"
net.inet.tcp.cc.algorithm=htcp  # (default newreno)

# host cache is the client's cached tcp connection details and metrics (TTL,
# SSTRESH and VARTTL) the server can use to improve future performance of
# connections between the same two hosts. When a tcp connection is completed,
# our server will cache information about the connection until an expire
# timeout. If a new connection between the same client is initiated before the
# cache has expired, the connection will use the cached connection details to
# setup the connection's internal variables. This pre-cached setup allows the
# client and server to reach optimal performance significantly faster because
# the server will not need to go through the usual steps of re-learning the
# optimal parameters for the connection. 3900 seconds allows clients who
# connect hourly to stay in our hostcache. To view the current host cache stats
# use "sysctl net.inet.tcp.hostcache.list"
# http://caia.swin.edu.au/reports/070717B/CAIA-TR-070717B.pdf
net.inet.tcp.hostcache.expire=3900  # (default 3600)

# somaxconn is the buffer or backlog queue depth for accepting new TCP
# connections. The default is 128 connections a second per application thread.
# Lets say your web server can accept 100 connections/sec and is single
# threaded. If clients are bursting in at a total of 250 connections per/sec
# you may want to set the somaxconn at 512 to be a 512 deep connection buffer
# so the extra 122 clients (250-128=122) do not get denied service by being
# sent a TCP RST packet. Also, a large listen queue will do a better job of
# avoiding Denial of Service (DoS) attacks if your application can handle the
# TCP load at the cost of more RAM and CPU time.
kern.ipc.somaxconn=1024  # (default 128)

# maximum segment size (MSS) specifies the largest amount of data in a single
# TCP segment:
# 1460 for a IPv4 1500 MTU network (MTU - 20 IPv4 header - 20 TCP header)
# 1440 for a IPv6 1500 MTU network (MTU - 40 IPv4 header - 20 TCP header)
# 8960 for a IPv4 9000 MTU network (MTU - 20 IPv4 header - 20 TCP header) and switch ports set at 9216
# 8940 for a IPv6 9000 MTU network (MTU - 40 IPv6 header - 20 TCP header) and switch ports set at 9216
# For most networks 1460 is optimal, but you may want to be cautious and use
# 1440. This smaller MSS allows an extra 20 bytes of space for those client
# which are on a DSL line which may use PPPoE. These networks have extra header
# data stored in the packet and if there is not enough space, must be
# fragmented over additional partially filled packets. Fragments cause extra
# processing which wastes time getting the data out to the remote machines.
# http://www.wand.net.nz/sites/default/files/mss_ict11.pdf
# We choose IPv4 network 1500 MTU - 40 bytes
net.inet.tcp.mssdflt=1460  # (default 536)

# Do not create a socket or compressed tcpw for TCP connections restricted to
# the local machine connecting to itself on localhost. An example connection
# would be a web server and a database server running on the same machine or
# freebsd jails connection to each other.
net.inet.tcp.nolocaltimewait=1  # (default 0)

# SlowStart Flightsize is TCP's initial congestion window as the number of
# packets on the wire at the start of the connection or after congestion.
# Google recommends ten(10), so an MTU of 1460 bytes times ten(10) initial
# congestion window is a 14.6 kilobyte data burst which is quite small for
# today's internet connections. If you are running FreeBSD 9.1 or earlier we
# recommend a value of 32 or higher. Note, slowstart_flightsize was removed
# from FreeBSD 9.2 and now we can only set the initial congestion window to 10.
# http://www.igvita.com/2011/10/20/faster-web-vs-tcp-slow-start/
net.inet.tcp.experimental.initcwnd10=1       # (default 0 for FreeBSD 9.2 only)
#net.inet.tcp.local_slowstart_flightsize=32  # (default 4 for FreeBSD 9.1 only)
#net.inet.tcp.slowstart_flightsize=32        # (default 4 for FreeBSD 9.1 only)

# The TCP window scale option is used to increase the TCP receive window size
# above its maximum value of 65,535 bytes (64k) as well as provide tcp time
# stamps allowing nearly every segment, including retransmissions, to be
# accurately timed at negligible computational cost.
net.inet.tcp.rfc1323=1  # (default 1)

# Make sure rfc3390 is disabled in FreeBSD 9.1 so the slowstart flightsize
# values above are used. In FreeBSD 9.2 the experimental.initcwnd10 has a
# higher priority then rfc3390 so we can keep rfc3390 on.
# http://lists.freebsd.org/pipermail/svn-src-head/2012-October/041733.html
net.inet.tcp.rfc3390=1  # (default 1)

# Generally, we suggest setting both send and receive space to slightly larger
# then 65535 if you have few incoming connections or a good amount of RAM;
# greater then 8 gig. If you are running a dedicated web server and do not
# accept large uploads it is recommend to leave the net.inet.tcp.recvspace as
# the FreeBSD default value. Then change the receive buffer for your
# web server's daemon in order to resist DDoS attacks taking up RAM with bogus
# connections. In nginx for example, set "listen 80 default rcvbuf=4k;" for
# small four(4) kilobyte receive buffers. If running a web server and you have
# a lot of spare ram then set the sendspace to the total size in bytes of a
# standard user request. For example, if a user requests your home page and it
# has 2 pictures, css and index.html equaling 212 kilobytes then set the
# sendspace to something like 262144 (256K). This will let the web server
# quickly dump the entire requested page set into the network buffer getting
# more data on the wire faster and freeing web server resources. By increasing
# the sendspace to a value larger then the whole page requested we saved 200ms
# on the web server client response time. Every millisecond counts.
net.inet.tcp.sendspace=262144  # (default 32768)
net.inet.tcp.recvspace=262144  # (default 65536)

# Increase auto-tuning TCP step size of the TCP transmit and receive buffers.
# The buffer starts at "net.inet.tcp.sendspace" and "net.inet.tcp.recvspace"
# and increases by these increments up to "net.inet.tcp.recvbuf_max" and
# "net.inet.tcp.sendbuf_max" as auto tuned by FreeBSD.
# http://fasterdata.es.net/host-tuning/freebsd/
net.inet.tcp.sendbuf_inc=262144  # (default 8192 )
net.inet.tcp.recvbuf_inc=262144  # (default 16384)

# Reduce the amount of SYN/ACKs we will re-transmit to an unresponsive client.
# On the initial connection our server will always send a SYN/ACK in response
# to the clients initial SYN. Limiting retranstited SYN/ACKS reduces local
# syn cache size and a "SYN flood" DoS attack's collateral damage by not sending
# SYN/ACKs back to spoofed ips multiple time. If we do continue to send
# SYN/ACKs to spoofed IPs they may send RST back to us and an "amplification"
# attack would begin against our host. If you do not wish to send retransmits
# at all then set to zero(0) especially if you are under a SYN attack.
# http://www.ouah.org/spank.txt
# http://people.freebsd.org/~jlemon/papers/syncache.pdf
net.inet.tcp.syncache.rexmtlimit=1  # (default 3)

# Syncookies have a certain number of advantages and disadvantages. Syncookies
# are useful if you are being DoS attacked as this method helps filter the
# proper clients from the attack machines. But, since the TCP options from the
# initial SYN are not saved in syncookies, the tcp options are not applied to
# the connection, precluding use of features like window scale, timestamps, or
# exact MSS sizing. As the returning ACK establishes the connection, it may be
# possible for an attacker to ACK flood a machine in an attempt to create a
# connection. Another benefit to overflowing to the point of getting a valid
# SYN cookie is the attacker can include data payload. Now that the attacker
# can send data to a FreeBSD network daemon, even using a spoofed source IP
# address, they can have FreeBSD do processing on the data which is not
# something the attacker could do without having SYN cookies. Even though
# syncookies are helpful during a DoS, we are going to disable them at this
# time.
net.inet.tcp.syncookies=0  # (default 1)

# Intel e1000 network card driver tuning
dev.em.0.fc=0                         # disable flow control for intel nics. many isp's abuse flow control to slow down
                                      # customers even though you are not using your full bandwidth. (default 3)

# General Security and DoS mitigation.
net.inet.ip.check_interface=1         # verify packet arrives on correct interface (default 0)
net.inet.ip.portrange.randomized=1    # randomize outgoing upper ports (default 1)
net.inet.ip.process_options=0         # IP options in the incoming packets will be ignored (default 1)
net.inet.ip.random_id=1               # assign a random IP_ID to each packet leaving the system (default 0)
net.inet.ip.redirect=0                # do not send IP redirects (default 1)
net.inet.ip.accept_sourceroute=0      # drop source routed packets since they can not be trusted (default 0)
net.inet.ip.sourceroute=0             # if source routed packets are accepted the route data is ignored (default 0)
net.inet.icmp.bmcastecho=0            # do not respond to ICMP packets sent to IP broadcast addresses (default 0)
net.inet.icmp.maskfake=0              # do not fake reply to ICMP Address Mask Request packets (default 0)
net.inet.icmp.maskrepl=0              # replies are not sent for ICMP address mask requests (default 0)
net.inet.icmp.log_redirect=0          # do not log redirected ICMP packet attempts (default 0)
net.inet.icmp.drop_redirect=1         # no redirected ICMP packets (default 0)
net.inet.icmp.icmplim=10              # number of ICMP/RST packets/sec to limit returned packet bursts during a DoS. (default 200)
net.inet.icmp.icmplim_output=1        # show "Limiting open port RST response" messages (default 1)
net.inet.tcp.drop_synfin=1            # SYN/FIN packets get dropped on initial connection (default 0)
net.inet.tcp.fast_finwait2_recycle=1  # recycle FIN/WAIT states quickly (helps against DoS, but may cause false RST) (default 0)
net.inet.tcp.icmp_may_rst=0           # icmp may not send RST to avoid spoofed icmp/udp floods (default 1)
net.inet.tcp.msl=3000                 # 3s maximum segment life waiting for an ACK in reply to a SYN-ACK or FIN-ACK (default 30000)
net.inet.tcp.path_mtu_discovery=0     # disable MTU discovery since most ICMP type 3 packets are dropped by others (default 1)
net.inet.tcp.rfc3042=0                # disable limited transmit mechanism which can slow burst transmissions (default 1)
net.inet.tcp.sack.enable=1            # TCP Selective Acknowledgments are needed for high throughput (default 1)
net.inet.udp.blackhole=1              # drop udp packets destined for closed sockets (default 0)
net.inet.tcp.blackhole=2              # drop tcp packets destined for closed ports (default 0)
security.bsd.see_other_uids=0         # only allow users to see their own processes. root can see all (default 1)

