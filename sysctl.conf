# $FreeBSD: stable/10/etc/sysctl.conf 112200 2003-03-13 18:43:50Z mux $
#
#  This file is read when going to multi-user and its contents piped thru
#  ``sysctl'' to adjust kernel values.  ``man 5 sysctl.conf'' for details.
#

# low latency is important so we highly recommend that you disable hyper
# threading on Intel CPUs as it has an unpredictable affect on latency, cpu
# cache misses and load.
#
# These settings are specifically tuned for a low latency FIOS (300/65) and
# gigabit LAN connections. If you have 10gig or 40gig you will need to increase
# the network buffers as well. 
#

# General network tuning
# https://wiki.freebsd.org/NetworkPerformanceTuning
kern.random.sys.harvest.ethernet=0
kern.random.sys.harvest.point_to_point=0
kern.random.sys.harvest.interrupt=0

# Before tuning the following two(2) sections on maxsockbuf and buf_max take a
# some time to read PSC's tips on Enabling High Performance Data Transfers.
# http://www.psc.edu/index.php/networking/641-tcp-tune

# set to at least 16MB for 10GE and high speed 1GE hosts as well as to increase
# the TCP window size to 65535 and window scale to 9. For 10GE hosts with RTT
# over 100ms you will need to set to 160MB and a wscale of 12. Default "2097152
# = 2*1024*1024" is fine for most 1Gbit connections or less.
# network:   1 Gbit   maxsockbuf:    2MB   wsize:  6    2^7*65KB =    8MB
# network:  10 Gbit   maxsockbuf:   16MB   wsize:  9    2^9*65KB =   32MB
# network:  40 Gbit   maxsockbuf:  150MB   wsize: 12   2^12*65KB =  260MB
# network: 100 Gbit   maxsockbuf:  600MB   wsize: 14   2^14*65KB = 1064MB
kern.ipc.maxsockbuf=16777216  # (default 2097152)

# set auto tuning maximum to at least 16MB for 10GE hosts with RTT of less then
# 100ms. For 10GE hosts with RTT of greater then 100ms set buf_max to 160MB.
# The default of  "2097152" is fine for 1Gb. 
net.inet.tcp.sendbuf_max=16777216  # (default 2097152)
net.inet.tcp.recvbuf_max=16777216  # (default 2097152)

# use the H-TCP congestion control algorithm which is more aggressive pushing
# up to max bandwidth (total BDP) and favors hosts with lower TTL / VARTTL then
# the default "newreno". Understand "newreno" works well in most conditions and
# enabling HTCP may only gain a you few percentage points of throughput. We
# suggest testing both, but we prefer HTCP.
# http://www.sigcomm.org/sites/default/files/ccr/papers/2008/July/1384609-1384613.pdf
# make sure to also add 'cc_htcp_load="YES"' to /boot/loader.conf then check
# available congestion control options with "sysctl net.inet.tcp.cc.available"
net.inet.tcp.cc.algorithm=htcp  # (default newreno)

# host cache is the client's cached tcp connection details and metrics (TTL,
# SSTRESH and VARTTL) the server can use to improve future performance of
# connections between the same two hosts. When a tcp connection is completed,
# our server will cache information about the connection until an expire
# timeout. If a new connection between the same client is initiated before the
# cache has expired, the connection will use the cached connection details to
# setup the connection's internal variables. This pre-cached setup allows the
# client and server to reach optimal performance significantly faster because
# the server will not need to go through the usual steps of re-learning the
# optimal parameters for the connection. 3900 seconds allows clients who
# connect hourly to stay in our hostcache. To view the current host cache stats
# use "sysctl net.inet.tcp.hostcache.list"
# http://caia.swin.edu.au/reports/070717B/CAIA-TR-070717B.pdf
net.inet.tcp.hostcache.expire=3900  # (default 3600)

# somaxconn is the buffer or backlog queue depth for accepting new TCP
# connections. The default is 128 connections a second per application thread.
# Lets say your web server can accept 100 connections/sec and is single
# threaded. If clients are bursting in at a total of 250 connections per/sec
# you may want to set the somaxconn at 512 to be a 512 deep connection buffer
# so the extra 122 clients (250-128=122) do not get denied service by being
# sent a TCP RST packet. Also, a large listen queue will do a better job of
# avoiding Denial of Service (DoS) attacks if your application can handle the
# TCP load at the cost of more RAM and CPU time. 
kern.ipc.somaxconn=1024  # (default 128)

# maximum segment size (MSS) specifies the largest amount of data in a single
# TCP segment:
# 1460 for a IPv4 1500 MTU network (MTU - 20 IPv4 header - 20 TCP header) 
# 1440 for a IPv6 1500 MTU network (MTU - 40 IPv4 header - 20 TCP header) 
# 8960 for a IPv4 9000 MTU network (MTU - 20 IPv4 header - 20 TCP header) and switch ports set at 9216
# 8940 for a IPv6 9000 MTU network (MTU - 40 IPv6 header - 20 TCP header) and switch ports set at 9216
# For most networks 1460 is optimal, but you may want to be cautious and use
# 1440. This smaller MSS allows an extra 20 bytes of space for those client
# which are on a DSL line which may use PPPoE. These networks have extra header
# data stored in the packet and if there is not enough space, must be
# fragmented over additional partially filled packets. Fragments cause extra
# processing which wastes time getting the data out to the remote machines.
# http://www.wand.net.nz/sites/default/files/mss_ict11.pdf
# We choose IPv4 network 1500 MTU - 40 bytes 
net.inet.tcp.mssdflt=1460  # (default 536)

# Do not create a socket or compressed tcpw for TCP connections restricted to
# the local machine connecting to itself on localhost. An example connection
# would be a web server and a database server running on the same machine or
# freebsd jails connection to each other. 
net.inet.tcp.nolocaltimewait=1  # (default 0)

# SlowStart Flightsize is TCP's initial congestion window as the number of
# packets on the wire at the start of the connection or after congestion.
# Google recommends ten(10), so an MTU of 1460 bytes times ten(10) initial
# congestion window is a 14.6 kilobyte data burst which is quite small for
# today's internet connections. If you are running FreeBSD 9.1 or earlier we
# recommend a value of 32 or higher. Note, slowstart_flightsize was removed
# from FreeBSD 9.2 and now we can only set the initial congestion window to 10.
# http://www.igvita.com/2011/10/20/faster-web-vs-tcp-slow-start/ 
net.inet.tcp.experimental.initcwnd10=1       # (default 0 for FreeBSD 9.2 only)
#net.inet.tcp.local_slowstart_flightsize=32  # (default 4 for FreeBSD 9.1 only)
#net.inet.tcp.slowstart_flightsize=32        # (default 4 for FreeBSD 9.1 only)

# The TCP window scale option is used to increase the TCP receive window size
# above its maximum value of 65,535 bytes (64k) as well as provide tcp time
# stamps allowing nearly every segment, including retransmissions, to be
# accurately timed at negligible computational cost.
net.inet.tcp.rfc1323=1  # (default 1)

# Make sure rfc3390 is disabled in FreeBSD 9.1 so the slowstart flightsize
# values above are used. In FreeBSD 9.2 the experimental.initcwnd10 has a
# higher priority then rfc3390 so we can keep rfc3390 on.
# http://lists.freebsd.org/pipermail/svn-src-head/2012-October/041733.html
net.inet.tcp.rfc3390=1  # (default 1)

# Generally, we suggest setting both send and receive space to slightly larger
# then 65535 if you have few incoming connections or a good amount of RAM;
# greater then 8 gig. If you are running a dedicated web server and do not
# accept large uploads it is recommend to leave the net.inet.tcp.recvspace as
# the FreeBSD default value. Then change the receive buffer for your
# web server's daemon in order to resist DDoS attacks taking up RAM with bogus
# connections. In nginx for example, set "listen 80 default rcvbuf=4k;" for
# small four(4) kilobyte receive buffers. If running a web server and you have
# a lot of spare ram then set the sendspace to the total size in bytes of a
# standard user request. For example, if a user requests your home page and it
# has 2 pictures, css and index.html equaling 212 kilobytes then set the
# sendspace to something like 262144 (256K). This will let the web server
# quickly dump the entire requested page set into the network buffer getting
# more data on the wire faster and freeing web server resources. By increasing
# the sendspace to a value larger then the whole page requested we saved 200ms
# on the web server client response time. Every millisecond counts.
net.inet.tcp.sendspace=262144  # (default 32768)
net.inet.tcp.recvspace=262144  # (default 65536)

# Increase auto-tuning TCP step size of the TCP transmit and receive buffers.
# The buffer starts at "net.inet.tcp.sendspace" and "net.inet.tcp.recvspace"
# and increases by these increments up to "net.inet.tcp.recvbuf_max" and
# "net.inet.tcp.sendbuf_max" as auto tuned by FreeBSD.
# http://fasterdata.es.net/host-tuning/freebsd/ 
net.inet.tcp.sendbuf_inc=262144  # (default 8192 )
net.inet.tcp.recvbuf_inc=262144  # (default 16384)

# Reduce the amount of SYN/ACKs we will re-transmit to an unresponsive client.
# On the initial connection our server will always send a SYN/ACK in response
# to the clients initial SYN. Limiting retranstited SYN/ACKS reduces local
# syn cache size and a "SYN flood" DoS attack's collateral damage by not sending
# SYN/ACKs back to spoofed ips multiple time. If we do continue to send
# SYN/ACKs to spoofed IPs they may send RST back to us and an "amplification"
# attack would begin against our host. If you do not wish to send retransmits
# at all then set to zero(0) especially if you are under a SYN attack.
# http://www.ouah.org/spank.txt
# http://people.freebsd.org/~jlemon/papers/syncache.pdf
net.inet.tcp.syncache.rexmtlimit=1  # (default 3)

# Syncookies have a certain number of advantages and disadvantages. Syncookies
# are useful if you are being DoS attacked as this method helps filter the
# proper clients from the attack machines. But, since the TCP options from the
# initial SYN are not saved in syncookies, the tcp options are not applied to
# the connection, precluding use of features like window scale, timestamps, or
# exact MSS sizing. As the returning ACK establishes the connection, it may be
# possible for an attacker to ACK flood a machine in an attempt to create a
# connection. Another benefit to overflowing to the point of getting a valid
# SYN cookie is the attacker can include data payload. Now that the attacker
# can send data to a FreeBSD network daemon, even using a spoofed source IP
# address, they can have FreeBSD do processing on the data which is not
# something the attacker could do without having SYN cookies. Even though
# syncookies are helpful during a DoS, we are going to disable them at this
# time.
net.inet.tcp.syncookies=0  # (default 1)

# Intel e1000 network card driver tuning
dev.em.0.fc=0                         # disable flow control for intel nics. many isp's abuse flow control to slow down
                                      # customers even though you are not using your full bandwidth. (default 3)

# General Security and DoS mitigation.
net.inet.ip.check_interface=1         # verify packet arrives on correct interface (default 0)
net.inet.ip.portrange.randomized=1    # randomize outgoing upper ports (default 1)
net.inet.ip.process_options=0         # IP options in the incoming packets will be ignored (default 1)
net.inet.ip.random_id=1               # assign a random IP_ID to each packet leaving the system (default 0)
net.inet.ip.redirect=0                # do not send IP redirects (default 1)
net.inet.ip.accept_sourceroute=0      # drop source routed packets since they can not be trusted (default 0)
net.inet.ip.sourceroute=0             # if source routed packets are accepted the route data is ignored (default 0)
net.inet.icmp.bmcastecho=0            # do not respond to ICMP packets sent to IP broadcast addresses (default 0)
net.inet.icmp.maskfake=0              # do not fake reply to ICMP Address Mask Request packets (default 0)
net.inet.icmp.maskrepl=0              # replies are not sent for ICMP address mask requests (default 0)
net.inet.icmp.log_redirect=0          # do not log redirected ICMP packet attempts (default 0)
net.inet.icmp.drop_redirect=1         # no redirected ICMP packets (default 0)
net.inet.icmp.icmplim=10              # number of ICMP/RST packets/sec to limit returned packet bursts during a DoS. (default 200)
net.inet.icmp.icmplim_output=1        # show "Limiting open port RST response" messages (default 1)
#net.inet.tcp.delayed_ack=1           # always employ delayed ack, 6 packets get 1 ack to increase bandwidth (default 1)
net.inet.tcp.drop_synfin=1            # SYN/FIN packets get dropped on initial connection (default 0)
#net.inet.tcp.ecn.enable=0            # explicit congestion notification (ecn) warning: some ISP routers abuse it (default 0)
net.inet.tcp.fast_finwait2_recycle=1  # recycle FIN/WAIT states quickly (helps against DoS, but may cause false RST) (default 0)
net.inet.tcp.icmp_may_rst=0           # icmp may not send RST to avoid spoofed icmp/udp floods (default 1)
#net.inet.tcp.maxtcptw=15000          # max number of tcp time_wait states for closing connections (default 5120)
net.inet.tcp.msl=3000                 # 3s maximum segment life waiting for an ACK in reply to a SYN-ACK or FIN-ACK (default 30000)
net.inet.tcp.path_mtu_discovery=0     # disable MTU discovery since most ICMP type 3 packets are dropped by others (default 1)
net.inet.tcp.rfc3042=0                # disable limited transmit mechanism which can slow burst transmissions (default 1)
net.inet.tcp.sack.enable=1            # TCP Selective Acknowledgments are needed for high throughput (default 1)
net.inet.udp.blackhole=1              # drop udp packets destined for closed sockets (default 0)
net.inet.tcp.blackhole=2              # drop tcp packets destined for closed ports (default 0)
#net.route.netisr_maxqlen=4096        # route queue length (rtsock using "netstat -Q") (default 256)
security.bsd.see_other_uids=0         # only allow users to see their own processes. root can see all (default 1)

#
# #
#   #
######### OFF BELOW HERE #########
#
# Other options not enabled, but included for future reference. The following
# may be needed in high load environments or against DDOS attacks. Take a look
# at the detailed comments for more information and make an informed decision.

# security settings for jailed environments. it is generally a good idea to
# separately jail any service which is accessible by an external client like
# the web or mail server. This is especially true for public facing services.
# take a look at ezjail, http://forums.freebsd.org/showthread.php?t=16860
#security.jail.allow_raw_sockets=1       # (default 0)
#security.jail.enforce_statfs=2          # (default 2)
#security.jail.set_hostname_allowed=0    # (default 1)
#security.jail.socket_unixiproute_only=1 # (default 1)
#security.jail.sysvipc_allowed=0         # (default 0)
#security.jail.chflags_allowed=0         # (default 0)

# Spoofed packet attacks may be used to overload the kernel route cache. A
# spoofed packet attack using a random source IP will cause the kernel to
# generate a temporary cached route in the route table, Setting rtexpire and
# rtminexpire to two(2) seconds should be sufficient to protect the route table
# from attack. 
# http://www.freebsd.org/doc/en/books/handbook/securing-freebsd.html
#net.inet.ip.rtexpire=60      # (default 3600)
#net.inet.ip.rtminexpire=2    # (default 10  )
#net.inet.ip.rtmaxcache=1024  # (default 128 )

# decrease the scheduler maximum time slice for lower latency program calls.
# by default we use stathz/10 which equals thirteen(13). also, decrease the
# scheduler maximum time for interactive programs as this is a dedicated
# server (default 30). Also make sure you look into "kern.hz=100" in /boot/loader.conf
#kern.sched.interact=5 # (default 30)
#kern.sched.slice=3    # (default 12)

# increase localhost network buffers. For example, if you run many high
# bandwidth services on lo0 like an http or local DB server and forward public
# external traffic using Pf. Also, if running many jails on lo0 then these may
# help. set to 10x(lo0 mtu 16384 + 40 bytes for header) = 164240
#net.local.stream.sendspace=164240  # (default 8192)
#net.local.stream.recvspace=164240  # (default 8192)

# ZFS L2ARC tuning - If you have read intensive workloads make sure to use an
# SSD for your L2ARC. Verify noprefetch is enabled(1) and increase the speed at
# which the system can fill the L2ARC device. By default, when the L2ARC is
# being populated FreeBSD will only write at 16MB/sec to the SSD. 16MB
# calculated by adding the speed of write_boost and write_max. 16MB/sec is way
# too slow as many SSD's made today which can easily sustain 256MB/sec. We
# highly recommend setting both write_boost and write_max to at least 256MB each
# so the L2ARC can be seeded quickly. Contrary to myth, enterprise class SSDs
# can last for many years under constant read/write abuse of a web server.
#vfs.zfs.l2arc_noprefetch=1          # (default 1)
#vfs.zfs.l2arc_write_boost=268435456 # (default 8388608)
#vfs.zfs.l2arc_write_max=268435456   # (default 8388608)

# ZFS - Set TXG write limit to a lower threshold. This helps "level out" the
# throughput rate (see "zpool iostat").  A value of 256MB works well for
# systems with 4 GB of RAM, while 1 GB works well for us w/ 8 GB on disks which
# have 64 MB cache.
#vfs.zfs.write_limit_override=1073741824

# This is a pure file server so commit async writes after 60 seconds if
# vfs.zfs.write_limit_max has not been reached by this timeout. Setting the
# timeout higher then the default 5 seconds leads to high load, bursting
# writes. If a user is on the system the machine system to be unresponsive.
# Test this before using.
#vfs.zfs.txg.timeout=60

# For slow drives, set outstanding vdev I/O to "1" to prevent parallel
# reads/writes per zfs vdev. By limiting read write streams we effectually force
# drive access into long sequential disk access for drives like a single
# 5400rpm disk. A value of one is not good for multiple disk spindles.
#vfs.zfs.vdev.min_pending="1"
#vfs.zfs.vdev.max_pending="1"

# Time before a delayed ACK is sent (default 100ms). By default, the ack is
# delayed 100 ms or sent every other packet in order to improve its chances of
# being added to a return data packet. This method can cut the number of tiny
# packets flowing across the network in half and is efficient. Setting
# delayed_ack to zero(0) will produce twice as many small packets on the
# network without much benefit. Setting delacktime higher then 100 seems to
# slow down downloads as ACKs are queued too long.
#net.inet.tcp.delayed_ack=1   # 1 default
#net.inet.tcp.delacktime=100  # 100 default

# maximum incoming and outgoing ip4 network queue sizes. if, and only if,
# "sysctl net.inet.ip.intr_queue_drops" is greater
# then zero increase these values till queue_drops is always zero(0).
#net.inet.ip.intr_queue_maxlen=4096
#net.route.netisr_maxqlen=4096

# UFS hard drive read ahead equivalent to 4 MiB at 32KiB block size. Easily
# increases read speeds from 60 MB/sec to 80 MB/sec on a single spinning hard
# drive. Samsun 830 SSD drives went from 310 MB/sec to 372 MB/sec (SATA 6).
# use bonnie to performance test file system I/O
#vfs.read_max=128

# global limit for number of sockets in the system. If kern.ipc.numopensockets
# plus net.inet.tcp.maxtcptw is close to kern.ipc.maxsockets then increase this
# value
#kern.ipc.maxsockets = 25600

# spread tcp timer callout load evenly across cpus. We did not see any speed
# benefit from enabling per cpu timers. The default is off(0)
#net.inet.tcp.per_cpu_timers = 0

# Increase maxdgram length for jumbo frames (9000 mtu) OSPF routing. Safe for
# 1500 mtu too.
#net.inet.raw.maxdgram=9216
#net.inet.raw.recvspace=9216 

# seeding cryptographic random number generators is provided by the /dev/random
# device, which provides psudo "real" randomness. The arc4random(3) library call
# provides a pseudo-random sequence which is generally reckoned to be suitable
# for simple cryptographic use. The OpenSSL library also provides functions for
# managing randomness via functions such as RAND_bytes(3) and RAND_add(3). Note
# that OpenSSL uses the random device /dev/random for seeding automatically.
# http://manpages.ubuntu.com/manpages/lucid/man4/random.4freebsd.html
#kern.random.yarrow.gengateinterval=10  # default 10 [4..64]
#kern.random.yarrow.bins=10             # default 10 [2..16]
#kern.random.yarrow.fastthresh=192      # default 192 [64..256]
#kern.random.yarrow.slowthresh=256      # default 256 [64..256]
#kern.random.yarrow.slowoverthresh=2    # default 2 [1..5]
#kern.random.sys.seeded=1               # default 1
#kern.random.sys.harvest.ethernet=1     # default 1
#kern.random.sys.harvest.point_to_point=1 # default 1
#kern.random.sys.harvest.interrupt=1    # default 1
#kern.random.sys.harvest.swi=0          # default 0 and actually does nothing when enabled

# IPv6 Security
# For more info see http://www.fosslc.org/drupal/content/security-implications-ipv6
# Disable Node info replies
# To see this vulnerability in action run `ping6 -a sglAac ::1` or `ping6 -w ::1` on unprotected node
#net.inet6.icmp6.nodeinfo=0
# Turn on IPv6 privacy extensions
# For more info see proposal http://unix.derkeiler.com/Mailing-Lists/FreeBSD/net/2008-06/msg00103.html
#net.inet6.ip6.use_tempaddr=1
#net.inet6.ip6.prefer_tempaddr=1
# Disable ICMP redirect
#net.inet6.icmp6.rediraccept=0
# Disable acceptation of RA and auto linklocal generation if you don't use them
##net.inet6.ip6.accept_rtadv=0
##net.inet6.ip6.auto_linklocal=0

##
### EOF ###


